---
title: "Estimating Population Size"
author: "Eamonn O'Brien"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  pdf_document:
    toc: true
    toc_depth: 2
  fig_height: 6
  fig_width: 8
header-includes:
- \usepackage{eso-pic,graphicx,transparent}
- \usepackage{graphicx}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \setlength\headheight{22pt}
- \fancyfoot[RO]{Estimating Population Size}
- \usepackage{lastpage}
- \cfoot{Page \thepage\ of \pageref{LastPage}}
---

\newpage  
\tableofcontents  
\listoffigures
\listoftables
\newpage

```{r set-options, echo=FALSE, cache=FALSE, warning = FALSE}

 

         set.seed(123)
        startTime<-proc.time()
        library(knitr)
         options(width=60)

         opts_chunk$set(comment = "", warning = FALSE, message = FALSE,
                       echo = TRUE, tidy = TRUE, size="tiny",  cache=FALSE,
                       progress=TRUE, tidy.opts=list(width.cutoff=60),
                         fig.width=7, fig.height=3.5,
                       cache.path = 'program_Cache/',
                       fig.path='figure/')
         
        # opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE) 
         
        knitr::knit_hooks$set(inline = function(x) {
          knitr:::format_sci(x, 'md')
        })
         
        
        options(scipen=999)  # remove scientific notation
        

        
        
 
```

```{r ,echo=FALSE}

p2 <- function(x) {formatC(x, format="f", digits=4)}

```

In any war, it is always of value to one side to have good intelligence on the weapons resources of the other side. During the Second World War, for example, Allied military planners eagerly searched for ways to accurately estimate the Axis production of tanks, aircrafts and numerous other weapons platforms. In the specific case of German tanks, a very clever way to do that was based on using either the stamped serial numbers or gearbox markings on captured Mark I and Mark V tanks, respectively. This type of problem has far wider applications.

We can experimentally see how well the formula that was used works in practice with a Monte Carlo Simulation. That is, the program first randomly picks a value for N (integer between 100 and 1000) with a value for the the sample size as a percentage of N.

The program then generates, randomly, n different integers in the interval 1 to N, the maximum of those integers is then used in the estimation formula to estimate a value for N. This estimate can be compared to the actual value of N to determine how well the formula has performed. We investigate samples that are 2%, 5%, 10% and 20% of the population.


## Function to implement Monte Carlo simulation using formula

```{r function}


runSim <- function(nSim=1000,  sample.size.perc=10/100 ) {
  
  #set up an array to store parameter estimates
  estArray <- array(0, dim=c(nSim,3))
  
  for (i in 1:nSim) {
    
    N <- sample(100:1000,1)  # select a population size
    
    n <- round(sample.size.perc*N,0) # the sample size
    
    sample2 <- sample(N, n) # select a sample from the population
    
    est <- (n+1)/n*max(sample2) - 1 # apply formula
    
    est <-  round(est ,0) # estimate of pop size
    
    estArray[i,1] <- (est - N)/ N *100  # percentage error is captured
    estArray[i,2] <- N
    estArray[i,3] <- sample.size.perc
    
  }
  
  list(estArray=estArray )
  
}

```

\newpage  

## Sample size 2% of population

```{r sample size 1}


  x<- runSim(nSim=10000,  sample.size.perc=2/100) # run simulation
  apply(x$estArray, 2, mean, na.rm=TRUE)[1]       # mean % error
  # median and 95% confidence intervals for % error
  quantile( x$estArray[,1] , prob=c(0.025, 0.5, 0.975))   
  hist(x$estArray[,1], breaks=100, main="Histogram of % error" , xlab="Percent error", ylab="No of simulations")     
  
```

\newpage  

## Sample size 5% of population

```{r sample size 2 }

  x<- runSim(nSim=10000,  sample.size.perc=5/100) # run simulation
  apply(x$estArray, 2, mean, na.rm=TRUE)[1]       # mean % error
  # median and 95% confidence intervals for % error
  quantile( x$estArray[,1] , prob=c(0.025, 0.5, 0.975))   
  hist(x$estArray[,1], breaks=100, main="Histogram of % error" , xlab="Percent error", ylab="No of simulations")               

```

\newpage  

## Sample size 10% of population

```{r sample size 3}

  x<- runSim(nSim=10000,  sample.size.perc=10/100) # run simulation
  apply(x$estArray, 2, mean, na.rm=TRUE)[1]       # mean % error
  # median and 95% confidence intervals for % error
  quantile( x$estArray[,1] , prob=c(0.025, 0.5, 0.975))   
    hist(x$estArray[,1], breaks=100, main="Histogram of % error" , xlab="Percent error", ylab="No of simulations")     
    
```

\newpage  

## Sample size 20% of population

```{r sample size 4}

  x<- runSim(nSim=10000,  sample.size.perc=20/100) # run simulation
  apply(x$estArray, 2, mean, na.rm=TRUE)[1]       # mean % error
  # median and 95% confidence intervals for % error
  quantile( x$estArray[,1] , prob=c(0.025, 0.5, 0.975))  
  hist(x$estArray[,1], breaks=100, main="Histogram of % error" , xlab="Percent error", ylab="No of simulations")              


```
\newpage  

## Computing Environment

```{r}

sessionInfo()

```

```{r echo=FALSE}

stopTime<-proc.time()

```

This took `r (stopTime-startTime)[1][[1]]` seconds to execute.

 